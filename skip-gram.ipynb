{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13092d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd7f567a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Example ='''The sun rose slowly over the quiet hills.\n",
    "    She placed her backpack by the door and sat down.\n",
    "    A cool breeze moved through the open window.\n",
    "    They finished their homework before dinner.\n",
    "    The dog waited patiently for its owner to return.\n",
    "    Rain tapped softly against the glass.\n",
    "    He wrote a reminder note and stuck it to the fridge.\n",
    "    The library was silent except for turning pages.\n",
    "    Fresh bread filled the kitchen with a warm smell.\n",
    "    The train arrived a few minutes early.'''\n",
    "Example = Example.split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30980c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Vec_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96b8be77",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = set(Example)\n",
    "words = list(words)\n",
    "V = len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02d0fd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_center_vectors = np.random.randn(V, Vec_size) * 0.01\n",
    "u_context_vectors = np.random.randn(V, Vec_size) * 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b69e5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_given_pair(cwvi, covi): # center word vector index, context word vector index\n",
    "    return u_context_vectors[covi].T @ v_center_vectors[cwvi] - np.log10(np.sum([np.exp(u_context_vectors[i].T @ v_center_vectors[covi]) for i in range(len(u_context_vectors))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73c438f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectoridx_with_wordidx(word_idx):\n",
    "    return words.index(Example[word_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77fe6d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelyhood_loss(cwi, context_window):\n",
    "    text_seq_sum = 0     \n",
    "    for index in range(2*context_window + 1):\n",
    "        if(index == cwi):\n",
    "            continue\n",
    "        coi = cwi + index - 2 \n",
    "        text_seq_sum += probability_given_pair(get_vectoridx_with_wordidx(cwi), get_vectoridx_with_wordidx(coi))\n",
    "    text_seq_sum *= -1 \n",
    "    return text_seq_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe229775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_center_vector(cwvi, covi):\n",
    "    v_c = v_center_vectors[cwvi]          \n",
    "    u_o = u_context_vectors[covi]        \n",
    "    scores = u_context_vectors @ v_c       \n",
    "    exp_scores = np.exp(scores)\n",
    "    probs = exp_scores / np.sum(exp_scores)\n",
    "\n",
    "    expected = np.sum(probs[:, np.newaxis] * u_context_vectors, axis=0)\n",
    "\n",
    "    grad = u_o - expected\n",
    "    return grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "202b7fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skipgram_sgd_step(cwvi, covi, lr=0.01):\n",
    "    global v_center_vectors, u_context_vectors\n",
    "    center_vector = v_center_vectors[cwvi]  \n",
    "    context_vector = u_context_vectors[covi] \n",
    "\n",
    "    scores = u_context_vectors @ center_vector\n",
    "    exp_scores = np.exp(scores)\n",
    "    probs = exp_scores / np.sum(exp_scores) \n",
    "\n",
    "    grad_vc = context_vector - np.sum(probs[:, np.newaxis] * u_context_vectors, axis=0)\n",
    "\n",
    "    grad_u = - probs[:, np.newaxis] * center_vector\n",
    "    grad_u[covi] += center_vector \n",
    "\n",
    "    v_center_vectors[cwvi] += lr * grad_vc\n",
    "    u_context_vectors += lr * grad_u\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81adf0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = {w: i for i, w in enumerate(words)}\n",
    "corpus_indices = [word2idx[w] for w in Example]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "430c4b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 2\n",
    "lr = 0.01\n",
    "\n",
    "epochs = 10000\n",
    "for i in range(epochs):\n",
    "    for center_pos, center_word_idx in enumerate(corpus_indices):\n",
    "        start = max(center_pos - window_size, 0)\n",
    "        end = min(center_pos + window_size + 1, len(corpus_indices))\n",
    "        \n",
    "        for context_pos in range(start, end):\n",
    "            if context_pos == center_pos:\n",
    "                continue\n",
    "            \n",
    "            context_word_idx = corpus_indices[context_pos]\n",
    "            \n",
    "            skipgram_sgd_step(center_word_idx, context_word_idx, lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2645ae97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import norm\n",
    "\n",
    "def nearest_neighbors(target_word, top_k=5):\n",
    "    idx = word2idx[target_word]\n",
    "    v_target = v_center_vectors[idx]\n",
    "    sims = []\n",
    "    for i, word in enumerate(words):\n",
    "        if i == idx:\n",
    "            continue\n",
    "        v = v_center_vectors[i]\n",
    "        cosine = np.dot(v_target, v) / (norm(v_target) * norm(v))\n",
    "        sims.append((word, cosine))\n",
    "    sims.sort(key=lambda x: x[1], reverse=True)\n",
    "    return sims[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aae7c3fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Rain', np.float64(0.589378120380917)),\n",
       " ('softly', np.float64(0.5099769320302998)),\n",
       " ('finished', np.float64(0.3939599926283824)),\n",
       " ('against', np.float64(0.3719396352272689)),\n",
       " ('by', np.float64(0.3168856860460859))]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nearest_neighbors(\"tapped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5f3bc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The oringin word was \n",
    "# ...... Rain tapped softly .........."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8beb42a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
